# ğŸ§  High Performance Computing (HPC) Roadmap

Welcome to my **HPC Mastery Roadmap** â€” an open learning journey to master the art of **building, optimizing, and deploying high-performance computing systems**.

---

## ğŸ¯ Goal
To gain deep expertise in:
- **Parallel Programming** (OpenMP, MPI)
- **GPU Computing** (CUDA, Numba, CuPy)
- **Cluster Architecture & Scheduling** (SLURM, PBS)
- **Cloud HPC** (AWS ParallelCluster, Kubernetes)
- **Performance Optimization** (profiling, scaling, hybrid parallelism)

---

## ğŸ“… Learning Phases

| Phase | Title | Duration | Focus | Progress |
|-------|--------|-----------|--------|-----------|
| 1 | [Core Foundations](phases/01_core_foundations.md) | 2 months | Systems, Linux, C/C++ | ğŸ”„ In Progress |
| 2 | [Parallel Programming](phases/02_parallel_programming.md) | 3 months | OpenMP, MPI | â³ Planned |
| 3 | [HPC Systems Architecture](phases/03_hpc_systems_architecture.md) | 2 months | Clusters, SLURM | â³ Planned |
| 4 | [GPU & Accelerator Computing](phases/04_gpu_accelerator_computing.md) | 2 months | CUDA, OpenCL | â³ Planned |
| 5 | [HPC in Cloud](phases/05_hpc_in_cloud.md) | 2 months | AWS ParallelCluster | â³ Planned |
| 6 | [Optimization & Research](phases/06_performance_optimization.md) | Continuous | Profiling, Scaling | â³ Planned |

---

## ğŸ§© Capstone Projects

| Project | Description | Technologies |
|----------|--------------|---------------|
| [1. Matrix Multiplication Benchmark](projects/project_1_matrix_multiplication.md) | Compare CPU vs parallel performance | C, Python, OpenMP |
| [2. Distributed Word Count](projects/project_2_distributed_wordcount.md) | MPI-based distributed computation | MPI, Python |
| [3. GPU Matrix Multiplication](projects/project_3_gpu_matrix_multiplication.md) | CUDA GPU acceleration | CUDA, CuPy |
| [4. Cloud-native HPC Pipeline](projects/project_4_cloud_native_hpc_pipeline.md) | Orchestrate parallel jobs in the cloud | AWS, Kubernetes |

---

## ğŸ§  Specialization Paths

| Focus | Description |
|--------|-------------|
| ğŸ§® **Scientific Computing** | CFD, FEA, Quantum Simulation |
| ğŸ’¸ **Computational Finance** | Monte Carlo, Risk Modelling |
| ğŸ¤– **AI/ML Acceleration** | Distributed training (Horovod, DeepSpeed) |
| â˜ï¸ **Cloud-native HPC DevOps** | SLURM + Kubernetes integration |

---

## ğŸ“š Resources

Check [resources/](resources/) for curated learning material:

- [Books](resources/books.md)
- [Courses](resources/courses.md)
- [Tools](resources/tools.md)
- [Research Papers](resources/research_papers.md)

---

## ğŸ§¾ Journal

Iâ€™m documenting weekly progress and reflections under the [journal/](journal/) folder.

Each entry includes:
- âœ… What I studied  
- ğŸ§  Key takeaways  
- âš™ï¸ Tools used  
- ğŸ§© Challenges and fixes  
- ğŸ¯ Next steps  

---

## âš¡ Tools & Technologies

| Category | Tools |
|-----------|--------|
| Parallel Programming | OpenMP, MPI, pthreads |
| GPU | CUDA, Numba, CuPy |
| Cluster Management | SLURM, PBS, Torque |
| Cloud HPC | AWS ParallelCluster, Kubernetes |
| Profiling | perf, gprof, Nsight, VTune |

---

## ğŸš€ Author
**Saurabh Asthana**  
Cloud & DevOps Engineer | Aspiring HPC & AI Researcher  
ğŸ“§ [iamsaurabhasthana@gmail.com](mailto:iamsaurabhasthana@gmail.com)

---

## ğŸŒŸ License
MIT License â€” free to fork, adapt, and contribute.

